{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCBgNbS8wACpZLIkLUI3BD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aceeesz/-Emerging-Technologies-1-in-CpE/blob/main/PRELIM_Emtech1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Christian Ed B. Efa\n",
        "#BSCPE31S2\n",
        "#PRELIM EMTEC CPE018"
      ],
      "metadata": {
        "id": "boQZYN1swL2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "MZ5oWorzu2nc",
        "outputId": "a5d24173-5eb1-4dab-a858-c9bf88b84997"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-88cddd373b4a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1. Abstracting a video stream with managers.CaptureManager\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#1. Abstracting a video stream with managers.CaptureManager\n",
        "import cv2\n",
        "import numpy\n",
        "import time\n",
        "\n",
        "class CaptureManager (object):\n",
        "    def _init_(self, capture, previewWindowManager = None, shouldMirrorPreview = False):\n",
        "        self.previewWindowManager = previewWindowManager\n",
        "        self.shouldMirrorPreview = shouldMirrorPreview\n",
        "\n",
        "        self._capture = capture\n",
        "        self._channel = 0\n",
        "        self._enteredFrame = False\n",
        "        self._frame = None\n",
        "        self._imageFilename = None\n",
        "        self._videoFilename = None\n",
        "        self._videoEncoding = None\n",
        "        self._videowriter = None\n",
        "        self._startTime = None\n",
        "        self._framesElapsed = 0\n",
        "        self._fpsEstimate = None\n",
        "\n",
        "    @property\n",
        "    def channel(self):\n",
        "        return self._channel\n",
        "\n",
        "    @channel.setter\n",
        "    def channel(self, value):\n",
        "        if self._channel != value:\n",
        "            self._channel = value\n",
        "            self._frame = None\n",
        "\n",
        "    @property\n",
        "    def frame(self):\n",
        "            if self. enteredFrane and self._frame is None:\n",
        "                _, self._frame = self._capture.retrieve()\n",
        "            return self._frame\n",
        "\n",
        "    @property\n",
        "    def isWritingImage(self):\n",
        "        return self._imageFilename is not None\n",
        "\n",
        "    @property\n",
        "    def iswritingVideo(self):\n",
        "        return self.videoFilename is not None\n",
        "\n",
        "    def enterFrame(self):\n",
        "\n",
        "        assert not self._enteredFrame, \\\n",
        "            'previous enterFrame() had no matching exitFrame()'\n",
        "\n",
        "        if self._capture is not None:\n",
        "            self._enteredframe = self._capture_grab()\n",
        "\n",
        "    def exitFrame(self):\n",
        "\n",
        "        if self.frame is None:\n",
        "            self._enteredFrame = False\n",
        "        return\n",
        "\n",
        "        if self._framesElapsed == 0:\n",
        "            self._startTime = time.time()\n",
        "        else:\n",
        "            timeElapsed = time.time() - self._startTime\n",
        "            self._fpsEstimate = self._framesElapsed / timeElapsed\n",
        "            self._framesElapsed += 1\n",
        "\n",
        "    #Draw to the window, if any.\n",
        "        if self.previewwindowManager is not None:\n",
        "            if self.shouldMirrorPreview:\n",
        "                mirroredFrame = numpy.fliplr(self._frame).copy()\n",
        "            self.previewWindowManager.show(mirroredFrame)\n",
        "        else:\n",
        "            self.previewwindowManager.show(self._frame)\n",
        "\n",
        "# write to the image file, if any.\n",
        "        if self.iswritingImage:\n",
        "            cv2.imwrite(self._imageFilename, self._frame)\n",
        "            self._ImageFilename = None\n",
        "\n",
        "#Write to the video file, if any.\n",
        "        self._writeVideoFrame()\n",
        "\n",
        "#Release the frame..\n",
        "        self._frame = None\n",
        "        self._enteredFrame = False\n",
        "\n",
        "def writeImage(self, filename):\n",
        "    \"\"\"Write the next exited frame to an image file.\"\"\"\n",
        "    self._imageFilename = filename\n",
        "\n",
        "def startWritingVideo(\n",
        "    self, filename,\n",
        "    encoding = cv2.VideoWriter_fourcc('I', '4', '2', '0')):\n",
        "    \"\"\"Start writing exited frames to a video file.\"\"\"\n",
        "    self._videoFilename = filename\n",
        "    self._videoEncoding = encoding\n",
        "\n",
        "def stopwritingVideo (self):\n",
        "    \"\"\"Stop writing exited frames to a video file.\"\"\"\n",
        "    self._videoFilename = None\n",
        "    self._videoEncoding = None\n",
        "    self._videoWriter = None\n",
        "def _writeVideoFrame(self):\n",
        "    if not self.iswritingVideo:\n",
        "        return\n",
        "\n",
        "    if self._videoWriter is None:\n",
        "        fps = self._capture.get(cv2.CAP_PROP_FPS)\n",
        "        if fps == 0.0:\n",
        "#The capture's FPS is unknown so use an estimate.\n",
        "            if self._framesElapsed < 20:\n",
        "\n",
        "\n",
        "                return\n",
        "\n",
        "\n",
        "    else:\n",
        "        fps = self._fpsEstimate\n",
        "        size = (int(self._capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "      int(self._capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "    self._videoWriter = cv2.VideoWriter(self._videoFilename,\n",
        "                                        self._videoEncoding,\n",
        "                                        fps, size)\n",
        "\n",
        "    self._videoWriter.write(self._frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Abstracting a window and keyboard with managers.WindowManager\n",
        "import cv2\n",
        "import numpy\n",
        "import time\n",
        "\n",
        "class CaptureManager (object):\n",
        "    def _init_(self, capture, previewWindowManager = None, shouldMirrorPreview = False):\n",
        "        self.previewWindowManager = previewWindowManager\n",
        "        self.shouldMirrorPreview = shouldMirrorPreview\n",
        "\n",
        "        self._capture = capture\n",
        "        self._channel = 0\n",
        "        self._enteredFrame = False\n",
        "        self._frame = None\n",
        "        self._imageFilename = None\n",
        "        self._videoFilename = None\n",
        "        self._videoEncoding = None\n",
        "        self._videowriter = None\n",
        "        self._startTime = None\n",
        "        self._framesElapsed = 0\n",
        "        self._fpsEstimate = None\n",
        "\n",
        "    @property\n",
        "    def channel(self):\n",
        "        return self._channel\n",
        "\n",
        "    @channel.setter\n",
        "    def channel(self, value):\n",
        "        if self._channel != value:\n",
        "            self._channel = value\n",
        "            self._frame = None\n",
        "\n",
        "    @property\n",
        "    def frame(self):\n",
        "            if self. enteredFrane and self._frame is None:\n",
        "                _, self._frame = self._capture.retrieve()\n",
        "            return self._frame\n",
        "\n",
        "    @property\n",
        "    def isWritingImage(self):\n",
        "        return self._imageFilename is not None\n",
        "\n",
        "    @property\n",
        "    def iswritingVideo(self):\n",
        "        return self.videoFilename is not None\n",
        "\n",
        "    def enterFrame(self):\n",
        "\n",
        "        assert not self._enteredFrame, \\\n",
        "            'previous enterFrame() had no matching exitFrame()'\n",
        "\n",
        "        if self._capture is not None:\n",
        "            self._enteredframe = self._capture_grab()\n",
        "\n",
        "    def exitFrame(self):\n",
        "\n",
        "        if self.frame is None:\n",
        "            self._enteredFrame = False\n",
        "        return\n",
        "\n",
        "        if self._framesElapsed == 0:\n",
        "            self._startTime = time.time()\n",
        "        else:\n",
        "            timeElapsed = time.time() - self._startTime\n",
        "            self._fpsEstimate = self._framesElapsed / timeElapsed\n",
        "            self._framesElapsed += 1\n",
        "\n",
        "    #Draw to the window, if any.\n",
        "        if self.previewwindowManager is not None:\n",
        "            if self.shouldMirrorPreview:\n",
        "                mirroredFrame = numpy.fliplr(self._frame).copy()\n",
        "            self.previewWindowManager.show(mirroredFrame)\n",
        "        else:\n",
        "            self.previewwindowManager.show(self._frame)\n",
        "\n",
        "# write to the image file, if any.\n",
        "        if self.iswritingImage:\n",
        "            cv2.imwrite(self._imageFilename, self._frame)\n",
        "            self._ImageFilename = None\n",
        "\n",
        "#Write to the video file, if any.\n",
        "        self._writeVideoFrame()\n",
        "\n",
        "#Release the frame..\n",
        "        self._frame = None\n",
        "        self._enteredFrame = False\n",
        "\n",
        "def writeImage(self, filename):\n",
        "    \"\"\"Write the next exited frame to an image file.\"\"\"\n",
        "    self._imageFilename = filename\n",
        "\n",
        "def startWritingVideo(\n",
        "    self, filename,\n",
        "    encoding = cv2.VideoWriter_fourcc('I', '4', '2', '0')):\n",
        "    \"\"\"Start writing exited frames to a video file.\"\"\"\n",
        "    self._videoFilename = filename\n",
        "    self._videoEncoding = encoding\n",
        "\n",
        "def stopwritingVideo (self):\n",
        "    \"\"\"Stop writing exited frames to a video file.\"\"\"\n",
        "    self._videoFilename = None\n",
        "    self._videoEncoding = None\n",
        "    self._videoWriter = None\n",
        "def _writeVideoFrame(self):\n",
        "    if not self.iswritingVideo:\n",
        "        return\n",
        "\n",
        "    if self._videoWriter is None:\n",
        "        fps = self._capture.get(cv2.CAP_PROP_FPS)\n",
        "        if fps == 0.0:\n",
        "#The capture's FPS is unknown so use an estimate.\n",
        "            if self._framesElapsed < 20:\n",
        "\n",
        "\n",
        "                return\n",
        "\n",
        "\n",
        "    else:\n",
        "        fps = self._fpsEstimate\n",
        "        size = (int(self._capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "      int(self._capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "    self._videoWriter = cv2.VideoWriter(self._videoFilename,\n",
        "                                        self._videoEncoding,\n",
        "                                        fps, size)\n",
        "\n",
        "    self._videoWriter.write(self._frame)\n",
        "\n",
        "# Add the following to managers.py\n",
        "class WindowManager (object):\n",
        "    def _init_(self, windowName, keypressCallback = None):\n",
        "            self.keypressCallback = keypressCallback\n",
        "            self._windowName = windowName\n",
        "            self._isWindowCreated = False\n",
        "\n",
        "@property\n",
        "def isWindowCreated(self):\n",
        "    return self._isWindowCreated\n",
        "\n",
        "def createwindow (self):\n",
        "    cv2.namedWindow(self._windowName)\n",
        "    self._IsWindowCreated = True\n",
        "\n",
        "def show(self, frame):\n",
        "    cv2.imshow(self._windowName, frame)\n",
        "\n",
        "def destroyWindow (self):\n",
        "    cv2.destroywindow(self._windowName)\n",
        "    self._iswindowCreated = False\n",
        "\n",
        "def processEvents (self):\n",
        "    keycode = cv2.waitKey(1)\n",
        "    if self.keypressCallback is not None and keycode != -1:\n",
        "    # Discard any non-ASCII info encoded by GTK.\n",
        "        keycode & 0xFF\n",
        "        self.keypressCallback(keycode)\n"
      ],
      "metadata": {
        "id": "2AO7L7KJu_zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Applying everything with cameo.Cameo\n",
        "import cv2\n",
        "from managers import WindowManager, CaptureManager\n",
        "\n",
        "class Cameo(object):\n",
        "    def __init__(self):\n",
        "        self._windowManager = WindowManager('Cameo',self.onKeypress)\n",
        "        self._captureManager = CaptureManager(cv2.VideoCapture(0), self._windowManager, True)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Run the main loop.\"\"\"\n",
        "        self._windowManager.createWindow()\n",
        "        while self._windowManager.isWindowCreated:\n",
        "            self._captureManager.enterFrame()\n",
        "            frame = self._captureManager.frame\n",
        "            #TODO: Filter the frame\n",
        "            self._captureManager.exitFrame()\n",
        "            self._windowManager.processEvents()\n",
        "\n",
        "    def onKeypress (self, keycode):\n",
        "        \"\"\"Handle a keypress.\n",
        "        space Take a screenshot.\n",
        "        tab-> Start/stop recording a screencast.\n",
        "        escape Quit.\"\"\"\n",
        "        if keycode == 32: # space\n",
        "            self._captureManager.writeImage('screenshot.png')\n",
        "        elif keycode == 9: # tab\n",
        "            if not self._captureManager.isWritingVideo:\n",
        "                self._captureManager.startWritingVideo(\n",
        "                    'screencast.avi','xvid')\n",
        "\n",
        "            else:\n",
        "                self._captureManager.stopWritingVideo()\n",
        "        elif keycode == 27: # escape\n",
        "            self._windowManager.destroyWindow()\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    Cameo().run()\n"
      ],
      "metadata": {
        "id": "N3Xgsc7YvPyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Supplementary Task\n",
        "#Cameo Code\n",
        "import cv2\n",
        "from managers import WindowManager, CaptureManager\n",
        "from filters import strokeEdges, sharpenFilter, FindEdgesFilter, Blurfilter, EmbossFilter, ContourFilter, ContourDetection, circleDetection\n",
        "\n",
        "class Cameo(object):\n",
        "    def __init__(self):\n",
        "        self._windowManager = WindowManager('Cameo', self.onKeypress)\n",
        "        self._captureManager = CaptureManager(cv2.VideoCapture(0), self._windowManager, True)\n",
        "    def run(self):\n",
        "        self._windowManager.createWindow()\n",
        "        while self._windowManager.isWindowCreated:\n",
        "            self._captureManager.enterFrame()\n",
        "            frame = self._captureManager.frame\n",
        "\n",
        "            # Apply filters to the frame here\n",
        "            \"FindEdges Filter\"\n",
        "            filter = FindEdgesFilter()\n",
        "            filter.apply(frame, frame)\n",
        "\n",
        "            \"strokeEdges Filter\"\n",
        "            strokeEdges(frame, frame)\n",
        "\n",
        "            \"Sharpen Filter\"\n",
        "            filter = sharpenFilter()\n",
        "            filter.apply(frame, frame)\n",
        "\n",
        "            \"Blur Filter\"\n",
        "            blur_filter = Blurfilter()\n",
        "            blur_filter.apply(frame, frame)\n",
        "\n",
        "            \"Emboss FIlter\"\n",
        "            emboss = EmbossFilter()\n",
        "            emboss.apply(frame, frame)\n",
        "\n",
        "            \"Contour Filter\"\n",
        "            contour_filter = ContourFilter()\n",
        "            frame = contour_filter.apply(frame)\n",
        "\n",
        "            \"ContourDetection\"\n",
        "            frame = ContourDetection.apply(frame)\n",
        "\n",
        "            \"CircleDetection\"\n",
        "            frame = circleDetection(frame)\n",
        "\n",
        "            self._captureManager.exitFrame()\n",
        "            self._windowManager.processEvents()\n",
        "\n",
        "    def onKeypress(self, keycode):\n",
        "        if keycode == 32:\n",
        "            self._captureManager.writeImage('screenshot.png')\n",
        "        elif keycode == 9:\n",
        "            if not self._captureManager.isWritingVideo:\n",
        "                self._captureManager.startWritingVideo('screencast.avi')\n",
        "            else:\n",
        "                self._captureManager.stopWritingVideo()\n",
        "        elif keycode == 27:\n",
        "            self._windowManager.destroyWindow()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Cameo().run()\n"
      ],
      "metadata": {
        "id": "0OCwsTn1vPjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter Code\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "kernel = np.array([[-1, -1, -1],\n",
        "                   [-1, 9, -1],\n",
        "                   [-1, -1, -1]])\n",
        "\n",
        "def strokeEdges(src, dst, blurKsize=7, edgeKsize=5):\n",
        "    if blurKsize >= 3:\n",
        "        blurredSrc = cv2.medianBlur(src, blurKsize)\n",
        "        graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        graySrc = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.Laplacian(graySrc, cv2.CV_8U, graySrc, ksize=edgeKsize)\n",
        "    normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)\n",
        "    channels = cv2.split(src)\n",
        "    for channel in channels:\n",
        "        channel[:] = channel * normalizedInverseAlpha\n",
        "    cv2.merge(channels, dst)\n",
        "\n",
        "class VConvolutionFilter(object):\n",
        "    def __init__(self, kernel):\n",
        "        self._kernel = kernel\n",
        "    def apply(self, src, dst):\n",
        "        cv2.filter2D(src, -1, self._kernel, dst)\n",
        "\n",
        "class sharpenFilter(VConvolutionFilter):\n",
        "    def __init__(self):\n",
        "        kernel = np.array([[-1, -1, -1],\n",
        "                        [-1, 9, -1],\n",
        "                        [-1, -1, -1]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class FindEdgesFilter(VConvolutionFilter):\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = np.array([[-1, -1, -1],\n",
        "                        [-1, 8, -1],\n",
        "                        [-1, -1, -1]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class Blurfilter(VConvolutionFilter):\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = np.array([[0.02, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class EmbossFilter(VConvolutionFilter):\n",
        "\n",
        "  def __init__(self):\n",
        "    kernel = np.array([[-2, -1, 0],\n",
        "                       [-1, 1, 1],\n",
        "                       [0, 1, 2]])\n",
        "    VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "\n",
        "\n",
        "class ContourFilter:\n",
        "    @staticmethod\n",
        "    def apply(image):\n",
        "\n",
        "        gray_img = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
        "        ret, thresh = cv2.threshold(cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY), 150, 200, cv2.THRESH_BINARY_INV)\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        for c in contours:\n",
        "\n",
        "            x, y, w, h = cv2.boundingRect(c)\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "            rect = cv2.minAreaRect(c)\n",
        "\n",
        "            box = cv2.boxPoints(rect)\n",
        "\n",
        "            box = np.int0(box)\n",
        "\n",
        "            cv2.drawContours(image, [box], 0, (0, 0, 255), 3)\n",
        "\n",
        "            (x, y), radius = cv2.minEnclosingCircle(c)\n",
        "\n",
        "            center = (int(x), int(y))\n",
        "            radius = int(radius)\n",
        "\n",
        "            image = cv2.circle(image, center, radius, (0, 255, 0), 2)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "class ContourDetection:\n",
        "    @staticmethod\n",
        "    def apply(img):\n",
        "\n",
        "        cv2.pyrDown(img)\n",
        "        gray_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
        "        ret, thresh = cv2.threshold(cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY), 120, 220, cv2.THRESH_BINARY_INV)\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        grant = cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
        "        return img\n",
        "\n",
        "\n",
        "def circleDetection(src):\n",
        "    n = 37\n",
        "    gray_img = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.medianBlur(gray_img, n)\n",
        "    circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 3, 100, param1=150, param2=60, minRadius=50, maxRadius=50)\n",
        "\n",
        "    if circles is not None:\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        for i in circles[0, :]:\n",
        "\n",
        "            cv2.circle(src, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
        "\n",
        "            cv2.circle(src, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
        "    return src\n"
      ],
      "metadata": {
        "id": "U9maohlMv9FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Managers Code\n",
        "import cv2\n",
        "import numpy\n",
        "import time\n",
        "\n",
        "class CaptureManager(object):\n",
        "    def __init__(self, capture, previewWindowManager=None, shouldMirrorPreview=False):\n",
        "        self.previewWindowManager = previewWindowManager\n",
        "        self.shouldMirrorPreview = shouldMirrorPreview\n",
        "\n",
        "        self._capture = capture\n",
        "        self._channel = 0\n",
        "        self._enteredFrame = False\n",
        "        self._frame = None\n",
        "        self._imageFilename = None\n",
        "        self._videoFilename = None\n",
        "        self._videoEncoding = None\n",
        "        self._videowriter = None\n",
        "        self._startTime = None\n",
        "        self._framesElapsed = 0\n",
        "        self._fpsEstimate = None\n",
        "\n",
        "    @property\n",
        "    def channel(self):\n",
        "        return self._channel\n",
        "\n",
        "    @channel.setter\n",
        "    def channel(self, value):\n",
        "        if self._channel != value:\n",
        "            self._channel = value\n",
        "            self._frame = None\n",
        "\n",
        "    @property\n",
        "    def frame(self):\n",
        "        if self._enteredFrame and self._frame is None:\n",
        "            _, self._frame = self._capture.retrieve()\n",
        "        return self._frame\n",
        "\n",
        "    @property\n",
        "    def isWritingImage(self):\n",
        "        return self._imageFilename is not None\n",
        "\n",
        "    @property\n",
        "    def isWritingVideo(self):\n",
        "        return self._videoFilename is not None\n",
        "\n",
        "    def enterFrame(self):\n",
        "        assert not self._enteredFrame, 'previous enterFrame() had no matching exitFrame()'\n",
        "        if self._capture is not None:\n",
        "            self._enteredFrame = self._capture.grab()\n",
        "\n",
        "    def exitFrame(self):\n",
        "        if self.frame is None:\n",
        "            self._enteredFrame = False\n",
        "            return\n",
        "\n",
        "        if self._framesElapsed == 0:\n",
        "            self._startTime = time.time()\n",
        "        else:\n",
        "            timeElapsed = time.time() - self._startTime\n",
        "            self._fpsEstimate = self._framesElapsed / timeElapsed\n",
        "            self._framesElapsed += 1\n",
        "\n",
        "        if self.previewWindowManager is not None:\n",
        "            if self.shouldMirrorPreview:\n",
        "                mirroredFrame = numpy.fliplr(self._frame).copy()\n",
        "                self.previewWindowManager.show(mirroredFrame)\n",
        "            else:\n",
        "                self.previewWindowManager.show(self._frame)\n",
        "\n",
        "        if self.isWritingImage:\n",
        "            cv2.imwrite(self._imageFilename, self._frame)\n",
        "            self._imageFilename = None\n",
        "\n",
        "        self._writeVideoFrame()\n",
        "        self._frame = None\n",
        "        self._enteredFrame = False\n",
        "\n",
        "    def writeImage(self, filename):\n",
        "        \"\"\"Write the next exited frame to an image file.\"\"\"\n",
        "        self._imageFilename = filename\n",
        "\n",
        "    def startWritingVideo(self, filename, encoding=cv2.VideoWriter_fourcc('I', '4', '2', '0')):\n",
        "        \"\"\"Start writing exited frames to a video file.\"\"\"\n",
        "        self._videoFilename = filename\n",
        "        self._videoEncoding = encoding\n",
        "\n",
        "    def stopWritingVideo(self):\n",
        "        \"\"\"Stop writing exited frames to a video file.\"\"\"\n",
        "        self._videoFilename = None\n",
        "        self._videoEncoding = None\n",
        "        self._videoWriter = None\n",
        "\n",
        "    def _writeVideoFrame(self):\n",
        "        if not self.isWritingVideo:\n",
        "            return\n",
        "\n",
        "        if self._videoWriter is None:\n",
        "            fps = self._capture.get(cv2.CAP_PROP_FPS)\n",
        "            if fps == 0:\n",
        "                # The capture's FPS is unknown so use an estimate.\n",
        "                if self._framesElapsed < 20:\n",
        "                    return\n",
        "            else:\n",
        "                fps = self._fpsEstimate\n",
        "                size = (int(self._capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "                        int(self._capture.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "\n",
        "            self._videoWriter = cv2.VideoWriter(self._videoFilename,\n",
        "                                                self._videoEncoding,\n",
        "                                                fps, size)\n",
        "\n",
        "        self._videoWriter.write(self._frame)\n",
        "\n",
        "\n",
        "class WindowManager(object):\n",
        "    def __init__(self, windowName, keypressCallback=None):\n",
        "        self.keypressCallback = keypressCallback\n",
        "        self._windowName = windowName\n",
        "        self._isWindowCreated = False\n",
        "\n",
        "    @property\n",
        "    def isWindowCreated(self):\n",
        "        return self._isWindowCreated\n",
        "\n",
        "    def createWindow(self):\n",
        "        cv2.namedWindow(self._windowName)\n",
        "        self._isWindowCreated = True\n",
        "\n",
        "    def show(self, frame):\n",
        "        cv2.imshow(self._windowName, frame)\n",
        "\n",
        "    def destroyWindow(self):\n",
        "        cv2.destroyWindow(self._windowName)\n",
        "        self._isWindowCreated = False\n",
        "\n",
        "    def processEvents(self):\n",
        "        keycode = cv2.waitKey(1)\n",
        "        if self.keypressCallback is not None and keycode != -1:\n",
        "            # Discard any non-ASCII info encoded by GTK.\n",
        "            keycode & 0xFF\n",
        "            self.keypressCallback(keycode)\n"
      ],
      "metadata": {
        "id": "lM7NMGJiwE4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CannyEdge & Contour Detection\n",
        "#Cameo Code\n",
        "import cv2\n",
        "from managers import WindowManager, CaptureManager\n",
        "from filters import strokeEdges, sharpenFilter, FindEdgesFilter, Blurfilter, EmbossFilter, ContourFilter, ContourDetection, circleDetection, CannyEdgeDetection, ContourFilter\n",
        "\n",
        "class Cameo(object):\n",
        "    def __init__(self):\n",
        "        self._windowManager = WindowManager('Cameo', self.onKeypress)\n",
        "        self._captureManager = CaptureManager(cv2.VideoCapture(0), self._windowManager, True)\n",
        "    def run(self):\n",
        "        self._windowManager.createWindow()\n",
        "        while self._windowManager.isWindowCreated:\n",
        "            self._captureManager.enterFrame()\n",
        "            frame = self._captureManager.frame\n",
        "\n",
        "            # Apply filters to the frame here\n",
        "            \"FindEdges Filter\"\n",
        "            #filter = FindEdgesFilter()\n",
        "            #filter.apply(frame, frame)\n",
        "\n",
        "            \"strokeEdges Filter\"\n",
        "            #strokeEdges(frame, frame)\n",
        "\n",
        "            \"Sharpen Filter\"\n",
        "            #filter = sharpenFilter()\n",
        "            #filter.apply(frame, frame)\n",
        "\n",
        "            \"Blur Filter\"\n",
        "            #blur_filter = Blurfilter()\n",
        "            #blur_filter.apply(frame, frame)\n",
        "\n",
        "            \"Emboss FIlter\"\n",
        "            #emboss = EmbossFilter()\n",
        "            #emboss.apply(frame, frame)\n",
        "\n",
        "            \"Contour Filter\"\n",
        "            #contour_filter = ContourFilter()\n",
        "            #frame = contour_filter.apply(frame)\n",
        "\n",
        "            \"ContourDetection\"\n",
        "            #frame = ContourDetection.apply(frame)\n",
        "\n",
        "            \"CircleDetection\"\n",
        "            #frame = circleDetection(frame)\n",
        "\n",
        "            \"CannyEdgeDetection\"\n",
        "            #low_threshold = 100\n",
        "            #high_threshold = 200\n",
        "            #canny_detection = CannyEdgeDetection()\n",
        "            #edges = canny_detection.apply(frame, low_threshold, high_threshold)\n",
        "            #cv2.imshow('CannyEdgeDetection', edges)\n",
        "\n",
        "            \"ContourDetection\"\n",
        "            #frame = ContourDetection.apply(frame)\n",
        "\n",
        "            \"Contour Filter\"\n",
        "            contour_filter = ContourFilter()\n",
        "            frame = contour_filter.apply(frame)\n",
        "            self._captureManager.exitFrame()\n",
        "            self._windowManager.processEvents()\n",
        "\n",
        "    def onKeypress(self, keycode):\n",
        "        if keycode == 32:\n",
        "            self._captureManager.writeImage('screenshot.png')\n",
        "        elif keycode == 9:\n",
        "            if not self._captureManager.isWritingVideo:\n",
        "                self._captureManager.startWritingVideo('screencast.avi')\n",
        "            else:\n",
        "                self._captureManager.stopWritingVideo()\n",
        "        elif keycode == 27:\n",
        "            self._windowManager.destroyWindow()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Cameo().run()"
      ],
      "metadata": {
        "id": "Yth_mjZ61RwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CannyEdge & Contour Detection\n",
        "#Filter Code\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "kernel = np.array([[-1, -1, -1],\n",
        "                   [-1, 9, -1],\n",
        "                   [-1, -1, -1]])\n",
        "\n",
        "def strokeEdges(src, dst, blurKsize=7, edgeKsize=5):\n",
        "    if blurKsize >= 3:\n",
        "        blurredSrc = cv2.medianBlur(src, blurKsize)\n",
        "        graySrc = cv2.cvtColor(blurredSrc, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        graySrc = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "    cv2.Laplacian(graySrc, cv2.CV_8U, graySrc, ksize=edgeKsize)\n",
        "    normalizedInverseAlpha = (1.0 / 255) * (255 - graySrc)\n",
        "    channels = cv2.split(src)\n",
        "    for channel in channels:\n",
        "        channel[:] = channel * normalizedInverseAlpha\n",
        "    cv2.merge(channels, dst)\n",
        "\n",
        "class VConvolutionFilter(object):\n",
        "    def __init__(self, kernel):\n",
        "        self._kernel = kernel\n",
        "    def apply(self, src, dst):\n",
        "        cv2.filter2D(src, -1, self._kernel, dst)\n",
        "\n",
        "class sharpenFilter(VConvolutionFilter):\n",
        "    def __init__(self):\n",
        "        kernel = np.array([[-1, -1, -1],\n",
        "                        [-1, 9, -1],\n",
        "                        [-1, -1, -1]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class FindEdgesFilter(VConvolutionFilter):\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = np.array([[-1, -1, -1],\n",
        "                        [-1, 8, -1],\n",
        "                        [-1, -1, -1]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class Blurfilter(VConvolutionFilter):\n",
        "\n",
        "    def __init__(self):\n",
        "        kernel = np.array([[0.02, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01],\n",
        "                        [0.01, 0.01, 0.01, 0.01, 0.01]])\n",
        "        VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "class EmbossFilter(VConvolutionFilter):\n",
        "\n",
        "  def __init__(self):\n",
        "    kernel = np.array([[-2, -1, 0],\n",
        "                       [-1, 1, 1],\n",
        "                       [0, 1, 2]])\n",
        "    VConvolutionFilter.__init__(self, kernel)\n",
        "\n",
        "\n",
        "\n",
        "class ContourFilter:\n",
        "    @staticmethod\n",
        "    def apply(image):\n",
        "\n",
        "        gray_img = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
        "        ret, thresh = cv2.threshold(cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY), 150, 200, cv2.THRESH_BINARY_INV)\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        for c in contours:\n",
        "\n",
        "            x, y, w, h = cv2.boundingRect(c)\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "            rect = cv2.minAreaRect(c)\n",
        "\n",
        "            box = cv2.boxPoints(rect)\n",
        "\n",
        "            box = np.int0(box)\n",
        "\n",
        "            cv2.drawContours(image, [box], 0, (0, 0, 255), 3)\n",
        "\n",
        "            (x, y), radius = cv2.minEnclosingCircle(c)\n",
        "\n",
        "            center = (int(x), int(y))\n",
        "            radius = int(radius)\n",
        "\n",
        "            image = cv2.circle(image, center, radius, (0, 255, 0), 2)\n",
        "\n",
        "        return image\n",
        "\n",
        "\n",
        "class ContourDetection:\n",
        "    @staticmethod\n",
        "    def apply(img):\n",
        "\n",
        "        cv2.pyrDown(img)\n",
        "        gray_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
        "        ret, thresh = cv2.threshold(cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY), 120, 220, cv2.THRESH_BINARY_INV)\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        grant = cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
        "        return img\n",
        "\n",
        "\n",
        "def circleDetection(src):\n",
        "    n = 37\n",
        "    gray_img = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.medianBlur(gray_img, n)\n",
        "    circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 3, 100, param1=150, param2=60, minRadius=50, maxRadius=50)\n",
        "\n",
        "    if circles is not None:\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        for i in circles[0, :]:\n",
        "\n",
        "            cv2.circle(src, (i[0], i[1]), i[2], (0, 255, 0), 2)\n",
        "\n",
        "            cv2.circle(src, (i[0], i[1]), 2, (0, 0, 255), 3)\n",
        "    return src\n",
        "\n",
        "class CannyEdgeDetection:\n",
        "    @staticmethod\n",
        "    def apply(image, low_threshold, high_threshold):\n",
        "        gray_img = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)\n",
        "        edges = cv2.Canny(gray_img, low_threshold, high_threshold)\n",
        "        return edges\n",
        "\n",
        "class ContourDetection:\n",
        "    @staticmethod\n",
        "    def apply(img):\n",
        "\n",
        "        cv2.pyrDown(img)\n",
        "        gray_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
        "        ret, thresh = cv2.threshold(cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY), 120, 220, cv2.THRESH_BINARY_INV)\n",
        "        contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        grant = cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
        "        return img\n",
        "\n"
      ],
      "metadata": {
        "id": "7eN41gH-3F_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YLKmOeI53Btd"
      }
    }
  ]
}